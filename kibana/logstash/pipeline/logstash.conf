# logstash/pipeline/logstash.conf
input {
  file {
    path => "/app/logs/app_*.log"
    start_position => "beginning"
    sincedb_path => "/dev/null"
    codec => "plain"
    tags => ["app_logs"]
  }
}

filter {
  # 解析日期從檔案名稱
  if [path] {
    grok {
      match => { 
        "path" => "/app/logs/app_%{DATE:log_date}\.log" 
      }
    }
  }

  # 如果您的 log 有特定格式，可以在這裡添加 grok pattern
  # 例如：timestamp level message 的格式
  grok {
    match => { 
      "message" => "(?<timestamp>\d{4}-\d{2}-\d{2} \d{2}:\d{2}:\d{2}) \[%{LOGLEVEL:level}\] %{GREEDYDATA:log_message}"
    }
    tag_on_failure => ["_grokparsefailure"]
  }

  # 解析 timestamp 如果存在
  if [timestamp] {
    date {
      match => [ "timestamp", "yyyy-MM-dd HH:mm:ss" ]
      target => "@timestamp"
    }
  }

  # 添加 hostname 和其他 metadata
  mutate {
    add_field => { 
      "source_host" => "%{host}"
      "log_file" => "%{path}"
    }
  }
}

output {
  elasticsearch {
    hosts => ["elasticsearch:9200"]
    index => "app-logs-%{+YYYY.MM.dd}"
  }
  
  # 調試用，可以看到處理的日誌
  stdout { 
    codec => rubydebug 
  }
}